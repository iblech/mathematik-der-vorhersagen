=== Tag 0, abends

* Vorstellung
* Orgakram (u.a. Dokuforge)
* Motivation
* Mission/Plan: Videos und fertiges Ziffernprogramm

https://www.youtube.com/watch?v=MzJ0CytAsec
Windows Vista Speech Recognition Tested - Perl Scripting

https://www.youtube.com/watch?v=M1ONXea0mXg
Hound Internal Demo

https://www.youtube.com/watch?v=zsVsUvx8ieo
NVIDIA CES 2015 press conference: DRIVE PX Computer Vision (part 7)

https://www.youtube.com/watch?v=qv6UVOQ0F44
MarI/O - Machine Learning for Video Games


=== Tag 1: Analysis-Bootcamp

* Zwerge in einer Reihe
* Definition der Ableitung im Eindimensionalen
* Zwei Interpretationen: Steigung und lokale Approximation
* Ableitungsregeln, insbesondere Kettenregel
* Python: Gradientenabstieg

* Ableitung im Mehrdimensionalen
* Minimum finden
* Kettenregel
* Python: Mehrdimensionaler Gradientenabstieg


=== Tag 2: Python in Ruhe und LA-Bootcamp

* Variablen und for/range. Damit Zahlen von 1 bis 100 summieren, Quadratzahlen
  summieren.
* if. Damit Primzahlen bis 100 finden, Collatz-Vermutung testen.
* Listen. Damit Liste der ersten 100 Fibonacci-Zahlen erstellen.
* Danach Gradientenabstieg mit ansteigender Komplexität:
  1D/2D/nD, Gradientauswertung in ausgelagerter Funktion, ...

* Vektoren und Matrizen
* Matrixmultiplikation
* Übungsaufgaben zur Multiplikation (u.a. Demonstration von Nullteilern
  und Nichtkommutativität)
* Lösung linearer Gleichungssysteme (theoretisch und mit numpy.linalg.solve)


=== Tag 3, nur vormittags: Lineare Regression

* Lineare Regression, zunächst aber noch mit Gradientenabstieg statt
  Normalengleichung


=== Tag 4, nur nachmittags: Lineare Regression und neuronale Netze

* jetzt mit Herleitung und Programmierung der Normalengleichung
* Einstieg in neuronale Netze


=== Tag 5: Neuronale Netze

* Neuronale Netze mit einer einzigen Zwischenschicht, die aber beliebig
  viele Neuronen enthalten darf
* ???


=== Tag 6: Markov-Ketten und Rotationsvorbereitung

* Kurze Einführung in Markov-Ketten: Wie funktionieren sie? Beispiele.
* Wie zieht man aus Wahrscheinlichkeitsverteilungen?
* Programmieren in Python


=== Tag 7, nur nachmittags: Neuronale Netze

* XOR in Matrixschreibweise
* XOR-Training


=== Tag 8: Neuronale Netze und Projekte

* Fertigstellung der XOR-Trainings-Programme
* Weitere Entwicklungen bei neuronalen Netzen:
  * Stochastischer Gradientenabstieg
  * tanh-Neuronen
  * (Cross-Entropy-Kostenfunktion)
  * L2-Regularisierung um Overfitting zu begegnen
  * Convolutional Neural Networks
* Visualisierung von neuronalen Netzen und "Träume" von neuronalen Netzen
  http://googleresearch.blogspot.de/2015/06/inceptionism-going-deeper-into-neural.html
  http://www.matthewzeiler.com/pubs/arxive2013/eccv2014.pdf (Zeiler/Fergus: Visualizing and Understanding Convolutional Networks)
  https://www.youtube.com/watch?v=oyxSerkkP4o (Deep Dreaming Fear & Loathing in Las Vegas)

* Nachmittag???


=== Tag 9: Projekte

* Monte-Carlo-Simulationen
* Pseudoziffern
* Neuronales Netz, das eine Maus steuert, um zum Futter zu gelangen


=== Tag 10, nur vormittags: Verabschiedung

* :-(
* Zugausstieg verpassen


=== Wilde Ideen

* Bayes und Differentialgleichungen

  Denke an "Wohin bewegt sich ein abgestürztes Flugzeug auf dem Ozean".

  Sei f(t; a) sowas wie P(x(t) = a).

  f(t+h; a)
    = P(x(t+h) = a)
    = P(x(t) + x'(t) h = a)
    = P(x(t) = a - x'(t) h)
    = f(t; a - x'(t) h)
    = f(t; a) - f_2(t; a) x'(t) h

  Also: d/dt f(t; a) = -f_2(t; a) x'(t).

  Das Integral über a von f_2(t; a) x'(t) ist Null, die Normalisierung bleibt
  also erhalten.

* Brainstorm für "Mathe am Mittag" am Tag 0:

  Im Kurs:
  * Collatz-Vermutung
  * Unendliche Kettenbrüche, goldener Schnitt, Fibonacci-Zahlen
  * Buffons Nadel
  * Simpson-Paradoxon
  * Missinterpretation von Tests
  * Goodstein-Sequenzen
  * Brainfuck (die Programmiersprache)

  Für alle:
  * Rätselmittag: Zwerge in einer Reihe, Ameisen, blaue Augen, 100 Gefangene,
    Schrank und Schlümpfe, Smullyan
  * Quanten-Tic-Tac-Toe
  * Conways Armee

  Lang:
  * Fraktale programmieren
  * Haskell
  * Kryptographie
  * Unendlichkeit
  * Orbitalmechanik
